{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODE = 784 # 输入节点数\n",
    "OUTPUT_NODE = 10 # 输出节点数\n",
    "LAYER1_NODE = 500 # 隐含层节点数\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RETE_BASE = 0.8 # 基学习率\n",
    "LEARNING_RETE_DECAY = 0.99 # 学习率的衰减率\n",
    "REGULARIZATION_RATE = 0.0001 # 正则化项的权重系数\n",
    "TRAINING_STEPS = 10000 # 迭代训练次数\n",
    "MOVING_AVERAGE_DECAY = 0.99 # 滑动平均的衰减系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传入神经网络的权重和偏置，计算神经网络前向传播的结果\n",
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    # 判断是否传入ExponentialMovingAverage类对象\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1))\n",
    "                                      + avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2))\\\n",
    "                         + avg_class.average(biases2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络模型的训练过程\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None,INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    " \n",
    "    # 定义神经网络结构的参数\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE],\n",
    "                                               stddev=0.1))\n",
    "    biases1  = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE],\n",
    "                                               stddev=0.1))\n",
    "    biases2  = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    " \n",
    "    # 计算非滑动平均模型下的参数的前向传播的结果\n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False) # 定义存储当前迭代训练轮数的变量\n",
    " \n",
    "    # 定义ExponentialMovingAverage类对象\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "                        MOVING_AVERAGE_DECAY, global_step) # 传入当前迭代轮数参数\n",
    "    # 定义对所有可训练变量trainable_variables进行更新滑动平均值的操作op\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    " \n",
    "    # 计算滑动模型下的参数的前向传播的结果\n",
    "    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n",
    " \n",
    "    # 定义交叉熵损失值\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    # 定义L2正则化器并对weights1和weights2正则化\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    regularization = regularizer(weights1) + regularizer(weights2)\n",
    "    loss = cross_entropy_mean + regularization # 总损失值\n",
    " \n",
    "    # 定义指数衰减学习率\n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RETE_BASE, global_step,\n",
    "                    mnist.train.num_examples / BATCH_SIZE, LEARNING_RETE_DECAY)\n",
    "    # 定义梯度下降操作op，global_step参数可实现自加1运算\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate)\\\n",
    "                         .minimize(loss, global_step=global_step)\n",
    "    # 组合两个操作op\n",
    "    train_op = tf.group(train_step, variables_averages_op)\n",
    "    '''\n",
    "    # 与tf.group()等价的语句\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "    '''\n",
    "    # 定义准确率\n",
    "    # 在最终预测的时候，神经网络的输出采用的是经过滑动平均的前向传播计算结果\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    " \n",
    "    # 初始化回话sess并开始迭代训练\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # 验证集待喂入数据\n",
    "        validate_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n",
    "        # 测试集待喂入数据\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print('After %d training steps, validation accuracy'\n",
    "                      ' using average model is %f' % (i, validate_acc))\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x: xs, y_:ys})\n",
    " \n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print('After %d training steps, test accuracy'\n",
    "              ' using average model is %f' % (TRAINING_STEPS, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主函数\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "    train(mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "After 0 training steps, validation accuracy using average model is 0.076000\n",
      "After 1000 training steps, validation accuracy using average model is 0.978400\n",
      "After 2000 training steps, validation accuracy using average model is 0.980600\n",
      "After 3000 training steps, validation accuracy using average model is 0.982800\n",
      "After 4000 training steps, validation accuracy using average model is 0.983200\n",
      "After 5000 training steps, validation accuracy using average model is 0.984800\n",
      "After 6000 training steps, validation accuracy using average model is 0.984200\n",
      "After 7000 training steps, validation accuracy using average model is 0.984800\n",
      "After 8000 training steps, validation accuracy using average model is 0.985000\n",
      "After 9000 training steps, validation accuracy using average model is 0.985400\n",
      "After 10000 training steps, test accuracy using average model is 0.984500\n"
     ]
    }
   ],
   "source": [
    "main(argv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 当前的python文件是shell文件执行的入口文件，而非当做import的python module。\n",
    "# if __name__ == '__main__': # 在模块内部执行\n",
    "#     tf.app.run() # 调用main函数并传入所需的参数list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
